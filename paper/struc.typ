= Project Architecture
Im Rahmen des Projekts wurde eine modulare und reproduzierbare Forschungs- und Entwicklungsinfrastruktur für das Training und die Evaluation spielender Agenten entworfen und umgesetzt. Die Gesamtarchitektur ist bewusst in klar abgegrenzte Subprojekte unterteilt, wobei jedes Subprojekt eine wohldefinierte Aufgabe innerhalb der Pipeline übernimmt. Diese Trennung ermöglicht sowohl eine isolierte Weiterentwicklung einzelner Komponenten als auch eine flexible Kombination im Gesamtsystem. Aufgrund der geringen Modellkomplexität des zur Aktionsgenerierung eingesetzten Agents können mehrere Bots parallel betrieben werden, was eine effiziente gleichzeitige Simulation einer großen Anzahl von Agenten ermöglicht.

Die gesamte Infrastruktur ist CLI-basiert aufgebaut. Sämtliche Funktionalitäten von der Datensatzerzeugung über das Training bis hin zur Evaluation werden über CLI-Tools angesteuert. Dadurch wird eine hohe Automatisierbarkeit sowie eine einfache Integration in Skripte und Batch-Prozesse erreicht, was insbesondere für experimentelle Workflows von zentraler Bedeutung ist.

Zur Konfiguration der einzelnen Subsysteme werden TOML-Konfigurationsdateien und CLI-Argumente verwendet.

Ein zentraler Bestandteil des Projekts ist die Implementierung von spielenden Agenten, die gegeneinander antreten. Als Agent wurde die lib `gobang` verwendet, welche gezielt korrigiert wurde, um identifizierte Fehler zu beheben. Die Spiellogik selbst wurde eigenständig implementiert und basiert auf effizienten NumPy-Operationen, um eine performante und minimale Simulation großer Spielmengen zu ermöglichen. Zusätzlich werden die Agenten parallel in einem Thread-Pool ausgeführt, um die verfügbare Rechenleistung optimal auszunutzen und die Simulationsgeschwindigkeit weiter zu erhöhen.

Ergänzend dazu wurden mehrere spezialisierte Module entwickelt, darunter ein Render-Modul, welches vollständig headless arbeitet und somit ohne grafische Ausgabe auskommt, ein Modul zur Datensatzerzeugung durch automatisierte Spielsimulationen, ein Trainingsmodul für das Anlernen der Modelle, ein Evaluations- bzw. Testmodul zur quantitativen Bewertung des Agenten sowie dedizierte Upload- und Download-Skripte zur Verwaltung experimenteller Artefakte.

Im Verlauf des Projekts hat sich die Infrastruktur iterativ weiterentwickelt. Während zu Beginn viele Komponenten lokal und pfadbasiert organisiert waren, wurde dieses Vorgehen schrittweise durch eine zentrale Upload- und Download-Struktur über Hugging Face ersetzt. Diese Umstellung ermöglichte ortsunabhängigen Zugriff auf experimentelle Ergebnisse.

Darüber hinaus wurden im Entwicklungsprozess zahlreiche Variablen und Konfigurationen explorativ variiert. Da die erforderlichen GPU-Ressourcen ausschließlich auf dem Hochschulserver zur Verfügung standen, erfolgten diese Parameteranpassungen direkt dort. Dieses Vorgehen ermöglichte eine effiziente Exploration des Parameterraums, bevor stabile Konfigurationen finalisiert und zentral versioniert wurden.
